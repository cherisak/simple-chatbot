{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a015a00",
   "metadata": {},
   "source": [
    "# <center> Python Chatbot Project </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8329cc5",
   "metadata": {},
   "source": [
    "# What is a Chatbot ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf768f9",
   "metadata": {},
   "source": [
    "A chatbot, also called dialoguer or conversational agent, is an agent who dialogues with a user.\n",
    "Research on this person-machine interface is influenced by the competition on the Turing test (1950): giving the illusion that a program thinks through meaningful dialogue. A user is invited to formulate his request in natural language, it is refined by a friendly exchange, of which the software interprets an operational request for his information system . Chatbots therefore go beyond research or entertainment, they implement linguistic and psychological knowledge , and of course programming bases . [link](https://fr.wikipedia.org/wiki/Chatbot)\n",
    "\n",
    "A chatbot is an intelligent piece of software that is capable of communicating and performing actions similar to a human. Chatbots are used a lot in customer interaction, marketing on social network sites and instantly messaging the client. \n",
    "\n",
    "There are two basic types of chatbot models; *Retrieval based and Generative based models.*\n",
    "\n",
    "Deciding on the best technique for processing dialogue inputs and generating responses, is one of the first decisions you need to make. Most current systems use retrieval-based methods, while generative methods are still in research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2ad4d",
   "metadata": {},
   "source": [
    "### Retrieval based chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ca3bf",
   "metadata": {},
   "source": [
    "A retrieval-based chatbot uses predefined input patterns and responses. It then uses some type of heuristic approach to select the appropriate response. It is widely used in the industry to make goal-oriented chatbots where we can customize the tone and flow of the chatbot to drive our customers with the best experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21370351",
   "metadata": {},
   "source": [
    "### Generative based chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d518e",
   "metadata": {},
   "source": [
    "Generative models are not based on some predefined responses.\n",
    "\n",
    "They are based on seq 2 seq neural networks. It is the same idea as machine translation. In machine translation, we translate the source code from one language to another language but here, we are going to transform input into an output. It needs a large amount of data and it is based on Deep Neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cfb86",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698fac2d",
   "metadata": {},
   "source": [
    "Now it's time to understand what kind of data we will need to provide our chatbot with. Since this is a simple chatbot we don't need to download any massive datasets. We will just use data that we write ourselves. I'va called my file \"intents.json\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30edeace",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4a729",
   "metadata": {},
   "source": [
    "Before starting to work on our chatbot we need to download a few python packages.\n",
    "We will simply use pip to install the following:\n",
    "- numpy\n",
    "- nltk\n",
    "- tensorflow\n",
    "- tflearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce5b60",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d72288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "#nltk.download(\"punkt\") #uncomment to download\n",
    "#nltk.download(\"wordnet\") #uncomment to download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ce2c9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc0c45",
   "metadata": {},
   "source": [
    "### Reading the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c5c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open('./data/intents.json').read()\n",
    "data = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4acc426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intents\": [\n",
      "    {\n",
      "      \"tag\": \"greeting\",\n",
      "      \"patterns\": [\n",
      "        \"Hi\",\n",
      "        \"How are you\",\n",
      "        \"Is anyone there?\",\n",
      "        \"Hello\",\n",
      "        \"Good day\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"Hello, thanks for visiting\",\n",
      "        \"Good to see you again\",\n",
      "        \"Hi there, how can I help?\"\n",
      "      ],\n",
      "      \"context_set\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"goodbye\",\n",
      "      \"patterns\": [\n",
      "        \"Bye\",\n",
      "        \"See you later\",\n",
      "        \"Goodbye\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"See you later, thanks for visiting\",\n",
      "        \"Have a nice day\",\n",
      "        \"Bye! Come back again soon.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"thanks\",\n",
      "      \"patterns\": [\n",
      "        \"Thanks\",\n",
      "        \"Thank you\",\n",
      "        \"That's helpful\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"Happy to help!\",\n",
      "        \"Any time!\",\n",
      "        \"My pleasure\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"hours\",\n",
      "      \"patterns\": [\n",
      "        \"What hours are you open?\",\n",
      "        \"What are your hours?\",\n",
      "        \"When are you open?\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"We're open every day 9am-9pm\",\n",
      "        \"Our hours are 9am-9pm every day\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"payments\",\n",
      "      \"patterns\": [\n",
      "        \"Do you take credit cards?\",\n",
      "        \"Do you accept Mastercard?\",\n",
      "        \"Are you cash only?\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"We accept VISA, Mastercard and AMEX\",\n",
      "        \"We accept most major credit cards\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"tag\": \"opentoday\",\n",
      "      \"patterns\": [\n",
      "        \"Are you open today?\",\n",
      "        \"When do you open today?\",\n",
      "        \"What are your hours today?\"\n",
      "      ],\n",
      "      \"responses\": [\n",
      "        \"We're open every day from 9am-9pm\",\n",
      "        \"Our hours are 9am-9pm every day\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fed5a",
   "metadata": {},
   "source": [
    "So, as you can see, the dataset has an object called intents. The dataset has about 6 instances of intents, each having its own tag, context, patterns, and responses. If you thoroughly go through your dataset, you’ll understand that patterns are similar to the interactive statements that we expect from our users whereas responses are the replies to those statements. And, a tag is a one-word summary of the user’s query.\n",
    "\n",
    "Now, the task at hand is to make our machine learn the pattern between patterns and tags so that when the user enters a statement, it can identify the appropriate tag and give one of the responses as output. And, the following steps will guide you on how to complete this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb01fac",
   "metadata": {},
   "source": [
    "### Identifying Feature and Target for the NLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e10e5",
   "metadata": {},
   "source": [
    "Now, we will extract words from patterns and the corresponding tag to them.  \n",
    "We will use [nltk.word_tokenize](https://www.nltk.org/api/nltk.tokenize.html?highlight=word_tokenize#module-nltk.tokenize) to tokenize the words.   \n",
    "The words have been stored in data_X and the corresponding tag to it has been stored in data_Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7995c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3b97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60aa544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
